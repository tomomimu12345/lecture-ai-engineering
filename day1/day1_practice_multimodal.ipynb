{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# å®Ÿè·µæ¼”ç¿’ Day 1ï¼šstreamlitã¨FastAPIã®ãƒ‡ãƒ¢\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ä»¥ä¸‹ã®å†…å®¹ã‚’å­¦ç¿’ã—ã¾ã™ã€‚\n",
        "\n",
        "- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç’°å¢ƒè¨­å®š\n",
        "- Hugging Faceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸStreamlitã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª\n",
        "- FastAPIã¨ngrokã‚’ä½¿ç”¨ã—ãŸAPIã®å…¬é–‹æ–¹æ³•\n",
        "\n",
        "æ¼”ç¿’ã‚’å§‹ã‚ã‚‹å‰ã«ã€HuggingFaceã¨ngrokã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã€\n",
        "ãã‚Œãã‚Œã®APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "\n",
        "æ¼”ç¿’ã®æ™‚é–“ã§ã¯ã€ä»¥ä¸‹ã®3ã¤ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é †ã«èª¬æ˜ã—ã¾ã™ã€‚\n",
        "\n",
        "1. 01_streamlit_UI\n",
        "2. 02_streamlit_app\n",
        "3. 03_FastAPI\n",
        "\n",
        "2ã¤ç›®ã‚„3ã¤ç›®ã‹ã‚‰ã§ã‚‚å§‹ã‚ã‚‰ã‚Œã‚‹æ§˜ã«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "å¾©ç¿’ã®éš›ã«ã‚‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å½¹ç«‹ã¦ã¦ã„ãŸã ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ã€‚\n",
        "\n",
        "### æ³¨æ„äº‹é …\n",
        "ã€Œ02_streamlit_appã€ã¨ã€Œ03_FastAPIã€ã§ã¯ã€GPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã‚’å®Ÿè¡Œã™ã‚‹éš›ã¯ã€Google Colabç”»é¢ä¸Šã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œç·¨é›†ã€â†’ ã€Œãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®è¨­å®šã€\n",
        "\n",
        "ã€Œãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ã€ã®é …ç›®ã®ä¸­ã‹ã‚‰ã€ã€ŒT4 GPUã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€ŒCPUã€ã«ãªã£ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆ1~3å…±æœ‰ï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubã‹ã‚‰æ¼”ç¿’ç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’Cloneã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AIXMavdDEP8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12656322-37f7-48ba-8727-282d537d3e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lecture-ai-engineering'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 46 (delta 9), reused 5 (delta 5), pack-reused 16 (from 1)\u001b[K\n",
            "Receiving objects: 100% (46/46), 35.02 KiB | 3.89 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/matsuolab/lecture-ai-engineering.git\n",
        "!git clone https://github.com/tomomimu12345/lecture-ai-engineering.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "å¿…è¦ãªAPIãƒˆãƒ¼ã‚¯ãƒ³ã‚’.envã«è¨­å®šã—ã¾ã™ã€‚\n",
        "\n",
        "ã€Œlecture-ai-engineering/day1ã€ã®é…ä¸‹ã«ã€ã€Œ.env_templateã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "éš ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚è¡¨ç¤ºã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ç”»é¢å·¦å´ã®ã‚ã‚‹ã€ç›®ã®ã‚¢ã‚¤ã‚³ãƒ³ã®ã€Œéš ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤ºã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€Œ.env_templateã€ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã€Œ.envã€ã«å¤‰æ›´ã—ã¾ã™ã€‚ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªä¸­èº«ã«ãªã£ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"hf-********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ãƒ€ãƒ–ãƒ«ã‚¯ã‚ªãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ã‚’Huggingfaceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã€ngrokã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã§æ›¸ãå¤‰ãˆã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ãã‚Œãã‚Œã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒä½œæˆæ¸ˆã¿ã§ã‚ã‚Œã°ã€ä»¥ä¸‹ã®URLã‹ã‚‰ãã‚Œãã‚Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã§ãã¾ã™ã€‚\n",
        "\n",
        "- Huggingfaceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "æ›¸ãæ›ãˆãŸã‚‰ã€ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã®PCã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€Œ01_streamlit_UIã€ã‹ã‚‰ã€Œ02_streamlit_appã€ã¸é€²ã‚€éš›ã«ã€CPUã‹ã‚‰GPUã®åˆ©ç”¨ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ãŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒä¸€åº¦åˆ‡ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚\n",
        "\n",
        "ãã®éš›ã«ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ãŸã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯å†ä½œæˆã™ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€ãã®æ‰‹é–“ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠãã¨è‰¯ã„ã§ã™ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦è¨­å®šã—ã¾ã™ã€‚æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã€æœ€çµ‚çš„ã«ã€ŒTrueã€ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚Œã°ã†ã¾ãèª­ã¿è¾¼ã‚ã¦ã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bvEowFfg5lrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cb0960-eca2-4e2c-fa87-ab33134739ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m/content/lecture-ai-engineering/day1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "%cd /content/lecture-ai-engineering/day1\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0Yk6gaELSM"
      },
      "source": [
        "# 01_streamlit_UI\n",
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ01_streamlit_UIã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "S28XgOm0ELSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4caf70-9eeb-4223-881f-fee16f6b6c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/01_streamlit_UI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/01_streamlit_UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVp-aEIkELSM"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nBe41LFiELSN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyw6VHaTELSN"
      },
      "source": [
        "ngrokã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aYw1q0iXELSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5395d8bb-b27f-42be-d99c-9f3fe1405f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RssTcD_IELSN"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f-E7ucR6ELSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a809ba-8d43-4b81-f38c-111c2b3fd357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å…¬é–‹URL: https://9b87-34-141-197-20.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.141.197.20:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"å…¬é–‹URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYyXVFjELSN"
      },
      "source": [
        "å…¬é–‹URLã®å¾Œã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹URLã«ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€streamlitã®UIãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "app.pyã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚Œã¦ã„ã‚‹ç®‡æ‰€ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§ã€UIãŒã©ã®æ§˜ã«å¤‰åŒ–ã™ã‚‹ã‹ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n",
        "\n",
        "streamlitã®å…¬å¼ãƒšãƒ¼ã‚¸ã«ã¯ã€ã‚®ãƒ£ãƒ©ãƒªãƒ¼ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "streamlitã‚’ä½¿ã†ã¨pythonã¨ã„ã†ä¸€ã¤ã®è¨€èªã§ã‚ã£ã¦ã‚‚ã€æ§˜ã€…ãªUIã‚’å®Ÿç¾ã§ãã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚\n",
        "\n",
        "https://streamlit.io/gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtP5GLOELSN"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8Ek9QgahELSO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# 02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ02_streamlit_appã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UeEjlJ7uELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e5557e-787d-45e1-f673-d60538e1cd29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/02_streamlit_app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokã¨huggigfaceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jPxTiEWQELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df4667a-addb-42ad-80bb-7120e912134c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `LLM2024LASTColab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `LLM2024LASTColab`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitã§Huggingfaceã®ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’æ‰±ã†ãŸã‚ã«ã€streamlitç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.streamlitï¼‰ã‚’ä½œæˆã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã‚’æ ¼ç´ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚\n",
        "\n",
        "02_streamlit_appã§ã¯ã€Huggingfaceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã€åˆå›èµ·å‹•ã«ã¯2åˆ†ç¨‹åº¦æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã“ã®å¾…ã¡æ™‚é–“ã‚’åˆ©ç”¨ã—ã¦ã€app.pyã®ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVw7vKvL7_OQ",
        "outputId": "78a43d62-4499-40f7-8bf9-79042ad03bcf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-ftbrafvr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ftbrafvr\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 6daa3eeba582facb57cd71db8efb66998b12942f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11447517 sha256=ccedca5612981a5781b85b38ff0a307f44f71f98b114fecb64222e4012bca55c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-icny5h7z/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
            "Successfully built transformers\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed transformers-4.52.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBQyTTWTELSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0edb29f3-95c8-45fd-af0d-c8bff69f9158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å…¬é–‹URL: https://c060-34-141-197-20.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.141.197.20:8501\u001b[0m\n",
            "\u001b[0m\n",
            "NLTK loaded successfully.\n",
            "2025-04-21 10:41:59.830837: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745232119.856432    8324 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745232119.866770    8324 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-21 10:41:59.894192: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "model.safetensors: 100% 4.18G/4.18G [01:13<00:00, 56.9MB/s]\n",
            "generation_config.json: 100% 126/126 [00:00<00:00, 899kB/s]\n",
            "tokenizer_config.json: 100% 6.63k/6.63k [00:00<00:00, 26.2MB/s]\n",
            "vocab.json: 100% 2.78M/2.78M [00:00<00:00, 6.79MB/s]\n",
            "merges.txt: 100% 1.67M/1.67M [00:00<00:00, 5.01MB/s]\n",
            "tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 46.7MB/s]\n",
            "added_tokens.json: 100% 790/790 [00:00<00:00, 6.02MB/s]\n",
            "special_tokens_map.json: 100% 1.98k/1.98k [00:00<00:00, 15.7MB/s]\n",
            "chat_template.jinja: 100% 475/475 [00:00<00:00, 2.79MB/s]\n",
            "Device set to use cuda\n",
            "The model 'InternVLForConditionalGeneration' is not supported for text-generation. Supported models are ['PeftModelForCausalLM', 'AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
            "2025-04-21 10:43:42.428 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "2025-04-21 10:44:10.398 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "2025-04-21 10:46:28.234 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "/tmp/tmp0uhxpf2i.jpg\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1184x1238 at 0x7B92D86847D0>}, {'type': 'text', 'text': 'æ·»ä»˜ã—ãŸç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„'}]}]\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "[{'role': 'user', 'content': [{'type': 'image', 'image': '/tmp/tmpw45tmfwl.jpg'}, {'type': 'text', 'text': 'æ·»ä»˜ã—ãŸç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„'}]}]\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "[{'role': 'user', 'content': [{'type': 'image', 'image': 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg'}, {'type': 'text', 'text': 'æ·»ä»˜ã—ãŸç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„'}]}]\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "\u001b[31mâ”€â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â”€\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m640\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/lecture-ai-engineering/day1/02_streamlit_app/\u001b[0m\u001b[1;33mapp.py\u001b[0m:\u001b[94m48\u001b[0m in \u001b[92m<module>\u001b[0m          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mst.error(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mãƒ¢ãƒ‡ãƒ« \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mMODEL_NAME\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: \u001b[0m\u001b[33m{\u001b[0me\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mst.error(\u001b[33m\"\u001b[0m\u001b[33mGPUãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¸è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã™ã‚‹ã‹ \u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31mâ± \u001b[0m 48 model, processor, device = \u001b[1;4mload_model_and_processor\u001b[0m()                          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 49 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---\u001b[0m                                           \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 51 \u001b[0mst.title(\u001b[33m\"\u001b[0m\u001b[33mğŸ§  InternVL Chatbot with Image Input\u001b[0m\u001b[33m\"\u001b[0m)                               \u001b[31m \u001b[0m\n",
            "\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
            "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'load_model_and_processor'\u001b[0m is not defined\n",
            "2025-04-21 11:12:21.837 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "\u001b[31mâ”€â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â”€\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m640\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/lecture-ai-engineering/day1/02_streamlit_app/\u001b[0m\u001b[1;33mapp.py\u001b[0m:\u001b[94m48\u001b[0m in \u001b[92m<module>\u001b[0m          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mst.error(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mãƒ¢ãƒ‡ãƒ« \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mMODEL_NAME\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: \u001b[0m\u001b[33m{\u001b[0me\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)       \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mst.error(\u001b[33m\"\u001b[0m\u001b[33mGPUãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¸è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã™ã‚‹ã‹ \u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                            \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31mâ± \u001b[0m 48 \u001b[1;4mmodel, processor, device\u001b[0m = load_model()                                        \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 49 \u001b[0m                                                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---\u001b[0m                                           \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 51 \u001b[0mst.title(\u001b[33m\"\u001b[0m\u001b[33mğŸ§  InternVL Chatbot with Image Input\u001b[0m\u001b[33m\"\u001b[0m)                               \u001b[31m \u001b[0m\n",
            "\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0mcannot unpack non-iterable NoneType object\n",
            "2025-04-21 11:12:34.630 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "[{'role': 'user', 'content': [{'type': 'text', 'text': '100+22444='}]}]\n",
            "NLTK loaded successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "[{'role': 'user', 'content': [{'type': 'text', 'text': '100+22444='}]}]\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"å…¬é–‹URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ne1-Yb9ZaDd"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ©Ÿèƒ½ã¨ã—ã¦ã¯ã€ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚„å±¥æ­´é–²è¦§ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€Streamlitã«ã‚ˆã‚‹UIéƒ¨åˆ†ã ã‘ã§ã¯ãªãã€SQLiteã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ä¿å­˜ã‚„LLMã®ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—ãŸæ¨è«–ãªã©ã®å‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "- **`app.py`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã€å±¥æ­´é–²è¦§ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®UIã‚’æä¾›ã—ã¾ã™ã€‚\n",
        "- **`ui.py`**: ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚„å±¥æ­´é–²è¦§ãƒšãƒ¼ã‚¸ãªã©ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIãƒ­ã‚¸ãƒƒã‚¯ã‚’ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`llm.py`**: LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`database.py`**: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ãƒ»ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`metrics.py`**: BLEUã‚¹ã‚³ã‚¢ã‚„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãªã©ã€å›ç­”ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`data.py`**: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`config.py`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šï¼ˆãƒ¢ãƒ‡ãƒ«åã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰ã‚’ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`requirements.txt`**: ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUXhIzV7ELSP"
      },
      "source": [
        "# 03_FastAPI\n",
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ03_FastAPIã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ejjDLxr3kfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999757ab-a0ec-4330-a79b-ce00e381d7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/03_FastAPI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/03_FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45TDsNzELSQ"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uv6glCz5a7Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrmE2VmELSQ"
      },
      "source": [
        "ngrokã¨huggigfaceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELzWhMFORRIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4134c16e-6245-491e-8b2d-d12b62ffee36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `LLM2024LASTColab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `LLM2024LASTColab`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-wztc2CELSQ"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚\n",
        "\n",
        "ã€Œ02_streamlit_appã€ã‹ã‚‰ç¶šã‘ã¦ã€Œ03_FastAPIã€ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹å ´åˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒæ¸ˆã‚“ã§ã„ã‚‹ãŸã‚ã€ã™ãã«ã‚µãƒ¼ãƒ“ã‚¹ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã€Œ03_FastAPIã€ã®ã¿ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹å ´åˆã¯ã€åˆå›ã®èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå§‹ã¾ã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒçµ‚ã‚ã‚‹ã¾ã§æ•°åˆ†é–“å¾…ã¡ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meQ4SwISn3IQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140edbfe-1c6a-447f-8d45-b7c9d53e9b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-19 09:51:58.099245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745056318.126542    4248 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745056318.135765    4248 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-19 09:51:58.194301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ãƒ¢ãƒ‡ãƒ«åã‚’è¨­å®š: google/gemma-2-2b-jpn-it\n",
            "/content/lecture-ai-engineering/day1/03_FastAPI/app.py:134: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n",
            "FastAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®šç¾©ã—ã¾ã—ãŸã€‚\n",
            "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªngrokãƒˆãƒ³ãƒãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n",
            "ãƒãƒ¼ãƒˆ8501ã«æ–°ã—ã„ngrokãƒˆãƒ³ãƒãƒ«ã‚’é–‹ã„ã¦ã„ã¾ã™...\n",
            "---------------------------------------------------------------------\n",
            "âœ… å…¬é–‹URL:   https://8158-34-87-20-208.ngrok-free.app\n",
            "ğŸ“– APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (Swagger UI): https://8158-34-87-20-208.ngrok-free.app/docs\n",
            "---------------------------------------------------------------------\n",
            "(APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚„ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã«ã“ã®URLã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„)\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m4248\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "load_model_task: ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’é–‹å§‹...\n",
            "ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  8.89it/s]\n",
            "Device set to use cuda\n",
            "t=2025-04-19T09:52:12+0000 lvl=warn msg=\"failed to open private leg\" id=5ad09f22b550 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "t=2025-04-19T09:52:13+0000 lvl=warn msg=\"failed to open private leg\" id=d89524b182b8 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "ãƒ¢ãƒ‡ãƒ« 'google/gemma-2-2b-jpn-it' ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸ\n",
            "load_model_task: ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n",
            "èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8501\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mGET /docs HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mGET /openapi.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mGET /health HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mGET /health HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "ã‚·ãƒ³ãƒ—ãƒ«ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ä¿¡: prompt=string..., max_new_tokens=512\n",
            "ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’é–‹å§‹...\n",
            "ãƒ¢ãƒ‡ãƒ«æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n",
            "æŠ½å‡ºã•ã‚ŒãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”: 0 = \"Hello, World!\"\n",
            "print(f\"The message is: {string0}\")\n",
            "```\n",
            "\n",
            "This code snippet will:\n",
            "\n",
            "1. **Define a ...\n",
            "å¿œç­”ç”Ÿæˆæ™‚é–“: 13.19ç§’\n",
            "\u001b[32mINFO\u001b[0m:     2001:ce8:137:6721:c00c:8d3:add:81a6:0 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m4248\u001b[0m]\n",
            "\n",
            "ã‚µãƒ¼ãƒãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "\u001b[31mERROR\u001b[0m:    Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 699, in lifespan\n",
            "    await receive()\n",
            "GeneratorExit\n",
            "\n",
            "Task was destroyed but it is pending!\n",
            "task: <Task pending name='Task-2' coro=<LifespanOn.main() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/lifespan/on.py:78> wait_for=<Future cancelled>>\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\"status\":\"ok\",\"message\":\"Local LLM API is runnning\"}"
      ],
      "metadata": {
        "id": "etf_8I3Vd1s6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLubjIhbELSR"
      },
      "source": [
        "FastAPIãŒèµ·å‹•ã™ã‚‹ã¨ã€APIã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒé€šä¿¡ã™ã‚‹ãŸã‚ã®URLï¼ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰ãŒä½œã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "URLãŒä½œã‚‰ã‚Œã‚‹ã®ã¨åˆã‚ã›ã¦ã€Swagger UIã¨ã„ã†Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒä½œã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "Swagger UIã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã§ã€APIã®ä»•æ§˜ã‚’ç¢ºèªã§ããŸã‚Šã€APIã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "\n",
        "Swagger UIã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€APIã‚’é€šã—ã¦LLMã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgumW3mGELSR"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJymTZio-WPJ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Gx6vJgley1r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}